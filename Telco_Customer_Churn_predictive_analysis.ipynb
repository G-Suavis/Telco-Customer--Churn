{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"Telco_customer_churn.xlsx\" # Replace with your file path\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "# Drop irrelevant columns\n",
        "columns_to_drop = ['CustomerID', 'Country', 'State', 'City', 'Lat Long', 'Churn Reason', 'Churn Score']\n",
        "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Convert 'Churn Label' to numeric (0 for 'No', 1 for 'Yes')\n",
        "df['Churn Label'] = df['Churn Label'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Convert Total Charges to numeric\n",
        "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')\n",
        "df['Total Charges'] = df['Total Charges'].fillna(0)\n",
        "\n",
        "# Encode categorical variables\n",
        "binary_columns = ['Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Paperless Billing']\n",
        "label_encoders = {}\n",
        "for col in binary_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# One-hot encode multi-class columns\n",
        "multi_class_columns = ['Multiple Lines', 'Internet Service', 'Online Security', 'Online Backup',\n",
        "                       'Device Protection', 'Tech Support', 'Streaming TV', 'Streaming Movies',\n",
        "                       'Contract', 'Payment Method']\n",
        "df = pd.get_dummies(df, columns=multi_class_columns, drop_first=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['Churn Label', 'Churn Value'], errors='ignore')  # Drop both Churn Label and Churn Value\n",
        "y = df['Churn Label']  # Use Churn Label as the target variable\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Scale features for Logistic Regression\n",
        "scaler = StandardScaler()\n",
        "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled_scaled, y_resampled, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define models to compare\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
        "    \"SVM (Linear Kernel)\": SVC(kernel='linear', probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "# Compare models\n",
        "results = []\n",
        "for model_name, model in models.items():\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "    # Evaluate performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc_roc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else \"N/A\"\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Handle missing classes in report\n",
        "    precision_churn = report['1']['precision'] if '1' in report else 0.0\n",
        "    recall_churn = report['1']['recall'] if '1' in report else 0.0\n",
        "    f1_score_churn = report['1']['f1-score'] if '1' in report else 0.0\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"AUC-ROC\": auc_roc,\n",
        "        \"Precision (Churn)\": precision_churn,\n",
        "        \"Recall (Churn)\": recall_churn,\n",
        "        \"F1-Score (Churn)\": f1_score_churn\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"AUC-ROC\", ascending=False)\n",
        "print(results_df)\n",
        "\n",
        "# Save results to an Excel file\n",
        "results_df.to_excel(\"model_comparison_results.xlsx\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZY9k1xqAV7C",
        "outputId": "2a72be37-3e92-47de-cbf4-368fe0d1f162"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:37:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3624, number of negative: 3619\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002865 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1685\n",
            "[LightGBM] [Info] Number of data points in the train set: 7243, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500345 -> initscore=0.001381\n",
            "[LightGBM] [Info] Start training from score 0.001381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy   AUC-ROC  Precision (Churn)  Recall (Churn)  \\\n",
            "4             LightGBM  0.856039  0.939742           0.847950        0.867097   \n",
            "1        Random Forest  0.860548  0.938903           0.845820        0.881290   \n",
            "3              XGBoost  0.861836  0.938433           0.859987        0.863871   \n",
            "5  SVM (Linear Kernel)  0.825443  0.916343           0.836898        0.807742   \n",
            "0  Logistic Regression  0.822544  0.916022           0.828402        0.812903   \n",
            "2        Decision Tree  0.803543  0.803543           0.802835        0.803871   \n",
            "\n",
            "   F1-Score (Churn)  \n",
            "4          0.857416  \n",
            "1          0.863191  \n",
            "3          0.861925  \n",
            "5          0.822062  \n",
            "0          0.820580  \n",
            "2          0.803353  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import shap\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"Telco_customer_churn.xlsx\"  # Replace with your file path\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "# Drop irrelevant columns\n",
        "columns_to_drop = ['CustomerID', 'Country', 'State', 'City', 'Lat Long', 'Churn Reason', 'Churn Score']\n",
        "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Convert 'Churn Label' to numeric\n",
        "df['Churn Label'] = df['Churn Label'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Convert Total Charges to numeric\n",
        "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')\n",
        "df['Total Charges'] = df['Total Charges'].fillna(0)\n",
        "\n",
        "# Encode categorical variables\n",
        "binary_columns = ['Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Paperless Billing']\n",
        "label_encoders = {}\n",
        "for col in binary_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "multi_class_columns = ['Multiple Lines', 'Internet Service', 'Online Security', 'Online Backup',\n",
        "                       'Device Protection', 'Tech Support', 'Streaming TV', 'Streaming Movies',\n",
        "                       'Contract', 'Payment Method']\n",
        "df = pd.get_dummies(df, columns=multi_class_columns, drop_first=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['Churn Label', 'Churn Value'], errors='ignore')\n",
        "y = df['Churn Label']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model Feature Importance Extraction\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "feature_importance = pd.DataFrame({'Feature': X.columns})\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        # Tree-based models\n",
        "        feature_importance[model_name] = model.feature_importances_\n",
        "    elif hasattr(model, \"coef_\"):\n",
        "        # Logistic Regression\n",
        "        feature_importance[model_name] = np.abs(model.coef_[0])\n",
        "\n",
        "# Average Importance\n",
        "feature_importance['AverageImportance'] = feature_importance.iloc[:, 1:].mean(axis=1)\n",
        "feature_importance = feature_importance.sort_values(by='AverageImportance', ascending=False)\n",
        "\n",
        "print(\"Top Features Based on Average Importance:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "rfe = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=10)\n",
        "rfe.fit(X_train_scaled, y_train)\n",
        "rfe_features = X.columns[rfe.support_]\n",
        "print(\"\\nTop Features Identified by RFE:\")\n",
        "print(rfe_features)\n",
        "\n",
        "# SHAP Values for XGBoost\n",
        "explainer = shap.Explainer(models['XGBoost'], X_train_scaled)\n",
        "shap_values = explainer(X_train_scaled)\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
        "\n",
        "# Final Output\n",
        "final_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nFinal Selected Features for All Models:\")\n",
        "print(final_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "Oy1U-vgWmcfg",
        "outputId": "d887e210-24be-4bf0-94aa-d76a1fa39651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Telco_customer_churn.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-052d63b554af>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Telco_customer_churn.xlsx\"\u001b[0m  \u001b[0;31m# Replace with your file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Telco_customer_churn.xlsx'"
          ]
        }
      ]
    }
  ]
}